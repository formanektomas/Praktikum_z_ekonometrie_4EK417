%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {
\usetheme{Madrid}
\usefonttheme{serif} 
\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the 
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{color}
\usepackage[czech]{babel}
\usepackage{lmodern}  
\usepackage{rotating}
\usepackage{scrextend}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage{bm}
%
\newcommand{\Rko}{\texttt{R~}} 
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
\title[Block 4]{Praktikum z ekonometrie} % The short title appears at the bottom of every slide, the full title is only on the title page
\author{VŠE Praha} % Your name
\institute[4EK417] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
% Your institution for the title page
\medskip
\textit{Tomáš Formánek} % Your email address
}
\date{} % Date, can be changed to a custom date
%----------------------------------------------------------------------------------------
\begin{document}
\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}
%---------------------------------------------------------------------
\begin{frame}
\frametitle{Block 4 – Linear mixed effect models – Outline
} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%---------------------------------------------------------------------
\section{Introduction}
\begin{frame}{Introduction}
\small 
\textbf{Linear mixed effect model (LME)} -- generalization of linear (panel) model
\medskip
\begin{itemize}
\item LMEs \& longitudinal data: repeated measurements are performed on each individual  unit. Several units are sampled. Number of observations may differ across units (both longitudinal \& hierarchical data).\\ \smallskip
\quad $y_{ti}$ - observation at time $t$ for $i$-th individual. \\  
\quad $y_{ij}$ - $i$th observation of $j$th individual (if time aspect secondary). \\ 
\bigskip
\item LMEs \& nesting (hierarchical) data structures: data with two or more groups/levels of observations. \\ \smallskip
\quad $y_{ij}$ - observation for $i$-th company within $j$-th region. \\ 
\quad $y_{ij}$ - observation for $i$-th student within $j$-th class. \\ 
\medskip
We can group observations at multiple levels:\\
\smallskip
\quad $y_{tij}$ - measurement at time period $t$,  in region $i$ within state $j$.\\ 
\bigskip
\item Note how indices are ordered (left to right) from individual to highest level of aggregation. (alternative orderings exist in literature).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{Introduction}
\textbf{Linear mixed effect model (LME)} 
\medskip
\begin{itemize}
\item Nested/hierarchical structure of the LME model:
\medskip
\begin{itemize}
    \item Individual units $i$ (Level 1) are nested
    \medskip
    \item within $j$ groups (Level 2) with group-specific observation sizes $n_j$.
\end{itemize}
\medskip
\item One or more $\beta$-coefficients can vary across groups.
\bigskip
\item The same nesting/hierarchical framework applies to longitudinal data and their LME-based analysis:
\medskip
\begin{itemize}
    \item Observations at time $t$ (Level 1) are nested
    \smallskip
    \item within $j$ individual units (Level 2).
    \smallskip
    \item If appropriate, individual units can be nested in groups (Level 3) \dots 
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{Introduction}
\begin{itemize}
\item Mixed models are called ``mixed'', because the $\beta$-coefficients are \\a mix of fixed parameters and random variables
\smallskip 
\item Terms ``fixed'' and ``random'' have specific meaning for LMEs:\\ \smallskip
\begin{itemize}
\item A fixed coefficient is an unknown constant to be estimated. \smallskip
\item A random coefficient varies from ``group'' to ``group''. \\By ``group'', we mean Level 2 aggregation, if data have 2 levels. \\ - coefficients vary among schools (Level 2), not within school.\\
- coeffs. vary across individuals (Level 2), not over time (Level 1).
\end{itemize}
\smallskip
\item  LME models can have some added complexity:
\smallskip
\begin{itemize}
\item Multiple levels of nesting
\smallskip
\item Crossed random effects
\smallskip
\item Correlations between different random coefficients.


\end{itemize}
\smallskip
\item Random  coefficients are not estimated, but they can be predicted.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME model example}
\begin{frame}{LME model example}
\begin{itemize}
\item Data: \\London Education Authority Junior School Project
dataset, \\- we have 887 students ($i$) in 48 different schools ($j$),\\- we want to predict 5th-year math scores.
\medskip
\item We may start by ignoring the school grouping and any possible regressors -- we have a trivial model (\textit{single-mean} model):
$$ \texttt{math5}_{ij} = \beta_0~+~\varepsilon_{ij}, \quad i=1,\dots,n_j,  \quad j=1,\dots, M,  \quad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}) $$

where $M=48$ and $n_j$ differ among schools, $\texttt{math5}_{ij}$ is the observed  math score of $i$-th student at school $j$,
$\beta_0$ is the mean math score across our population (being sampled) and
$\varepsilon_{ij}$ is the individual deviation from overall mean.\\
\medskip
Population mean math score \& the variance of $\varepsilon$ are estimated by taking their sample counterparts. Any ``school effect'' is ignored.\\
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model example - continued}
\begin{itemize}
\item The school effect (differences among schools) may be incorporated in the model by allowing the mean of each school to be represented by a separate parameter (\textit{fixed effect})
$$ \texttt{math5}_{ij} = \beta_{0j}~+~\varepsilon_{ij}, \quad i=1,\dots,n_j,  \quad j=1,\dots, M,  \quad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}) $$

where $\beta_{0j}$ is the school-specific mean math score and
$\varepsilon_{ij}$ is the individual deviation from the school-specific mean.\\
\smallskip
\begin{itemize}
\item \Rko syntax: \texttt{lm(math5 $\sim$ School-1, data=...)}\\
$\Rightarrow~M=48$ school-specific intercepts are estimated.\\
\medskip
\item Using the terminology of LME, $\beta_{0j}$ are fixed. Hence:\\
\begin{itemize}
    \item \textbf{Estimated intercepts only model (refer to) the specific sample}  of schools, while -usually- the main interest is in the population from which the sample was drawn. \smallskip
    \item Regression does not provide an estimate of the between-school variability, which is also of central interest.
\end{itemize}
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept}
\begin{itemize}
\item \textit{Random effects} model can solve the above problems by treating the school effects as random variations around a population mean.
\medskip
\item \textit{Fixed effects} model can be reparametrized as: \\
\smallskip
\textcolor{blue}{$ y_{ij} = \beta_{0j} + \varepsilon_{ij}$} \\
\smallskip
$y_{ij} = \textcolor{orange}{\beta_0} + ( \beta_{0j} \textcolor{orange}{-\beta_0}) + \varepsilon_{ij}$,\\
\medskip
\textit{Random effect} $u_{0j} = \beta_{0j} - \beta_0$ is the school-specific deviation from overall mean $\beta_0$. It can be used to replace the the \textit{fixed effect} $\beta_{0j}\,$:\\
\medskip
$u_{0j} = \beta_{0j} - \beta_0 ~~~ \Rightarrow ~~~ \beta_{0j} = \beta_0 + u_{0j}.$ Hence:\\  \smallskip
\textcolor{blue}{$ y_{ij} = \beta_{0} + u_{0j} + \varepsilon_{ij}.$}\\
\medskip
\item $u_{0j}$ is a random variable, specific for the $j$-th school, with zero
mean and unknown variance $\sigma^2_u$. \\ 
$u_{0j}$ is a \textit{random effect}, associated with the particular sample units (schools are selected at random from the population).\\ 
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept}
\begin{itemize}
\item The \textit{random effects} model is given as:
$$ y_{ij} = \beta_{0} + u_{0j} + \varepsilon_{ij}, \qquad u_{0j} \sim N(0,\sigma^2_u), \qquad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}), $$
and we assume $u_{0j}$ are $iid$ and independent from $\varepsilon_{ij}$.\\
\smallskip
\begin{itemize}
\item Observations within the same school share the same random effect $u_{0j}$, hence are positively ``correlated'' with \textnormal{ICC} = $\sigma^2_u \, / (\sigma^2_u + \sigma^2_{\varepsilon})$ \\ (see ICC on next slide).
\medskip
\item This \textit{random effects} model has three parameters: $\beta_{0},~ \sigma^2_u$ and $\sigma^2_{\varepsilon}$. (regardless of $M$, the number of schools).
\medskip
\item Note that the \textit{random effect} $u_{0j}$ ``looks like'' a coefficient, but we are only interested in estimating $\sigma^2_u$.
\medskip
\item However, upon observed data (and estimated model), we do make predictions using fitted values of $\hat{u}_j$.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept and fixed slope}
\begin{itemize}
\item Exogenous regressors can be used in LMEs (like in LRMs).\\
\smallskip
For example, \texttt{math5} grades depend on \texttt{math3} ($3{^{\textnormal{rd}}}$ year grades).\\
\bigskip
$ \texttt{math5}_{ij} = \left( \beta_{0} + u_{0j} \right) + \beta_1 \, \texttt{math3}_{ij} + \varepsilon_{ij}, $\\
\medskip
alternatively: \\ \medskip
$ \texttt{math5}_{ij} = \beta_{0} + \beta_1 \, \texttt{math3}_{ij} + u_{0j} + \varepsilon_{ij}, $\\
\bigskip
\begin{itemize}
\item Intercept is random, given the $u_{0j}$ element.
\smallskip
\item Slope of the regression line for each school is fixed at $\beta_1$.\\
\dots \texttt{math3} has a \textit{fixed effect}.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model: ICC}
\small
\begin{itemize}
\item \textbf{ICC:} Intra class correlation in a LME regression model: \qquad
$$ \textnormal{ICC}=\frac{\sigma^2_u}{\sigma^2_u + \sigma^2_{\varepsilon}} $$
\begin{itemize}
    \item Describes how strongly units in the same group are ``correlated''.
    \item While interpreted as a type of correlation, ICC operates on groups, rather than paired observations. See \textcolor{blue}{\underline{\href{https://en.wikipedia.org/wiki/Intraclass_correlation}{Wikipedia}}} for formal definition \& relation between ICC and actual correlation.
\end{itemize}
\medskip
\item Example: \qquad $\texttt{math5}_{ij} = \beta_{0} + \beta_1 \, \texttt{math3}_{ij} + u_{0j} + \varepsilon_{ij},$\\ \medskip
\qquad \qquad \qquad ~where $\sigma^2_u = \textnormal{var}(u_{0j})$ and $\sigma^2_{\varepsilon} = \textnormal{var}(\varepsilon_{ij})$.\\ \smallskip
\medskip
\item Here, $\textnormal{ICC}$  measures ``correlation'' between \texttt{math5}  observations (randomly chosen) within a given school.\\ \smallskip \textbf{Note:} ICC has another useful interpretation. Say, ICC = 0.6 in our $\texttt{math5}_{ij}$ example. Hence, differences between schools explain 60\% of variance ``left over'' after the variance explained by fixed effects \\(i.e. by $\texttt{math3}_{ij}$).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept and slope}
\begin{itemize}
\item If teaching is different from school to school, it would make
sense to have different slopes for each of the schools.\\
\medskip
Instead of \textit{fixed effects} (using interaction terms \texttt{math3:School}), \\we use random slopes: $ u_{1j} = \beta_{1j} - \beta_1 $. \\
\bigskip
$ \texttt{math5}_{ij} = \left( \beta_{0} + u_{0j} \right) + \left( \beta_1\, \texttt{math3}_{ij}  + u_{1j} \, \texttt{math3}_{ij}  \right) + \varepsilon_{ij}, $ \\
\medskip
alternatively:\\
\medskip
$\texttt{math5}_{ij} = \underbrace{\beta_{0} + \beta_1 \,  \texttt{math3}_{ij}}_{\textit{fixed}}
+ \underbrace{u_{0j} + u_{1j} \, \texttt{math3}_{ij}}_{\textit{random}} 
+ \varepsilon_{ij}, $ \\
\bigskip
\begin{itemize}
\item We can test whether this extra complexity is justified.
\smallskip
\item ${u}_{0j}$ and ${u}_{1j}$ are often correlated, their independence can be tested.
\smallskip
\item Fitted values of $\texttt{math5}_{ij}$ can be produced, along with $\hat{u}_{0j}$ and $\hat{u}_{1j}$.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME model in matrix form}
\begin{frame}{LME model in matrix form}
\begin{itemize}
\item Linear models 
$$\bm{y} = \bm{X \beta} + \bm{\varepsilon} 
\qquad \bm{\varepsilon} \sim N(\bm{0}, \,\sigma^2_{\varepsilon} \bm{I}),$$

\item can be generalized into LME models
$$\bm{y} = \bm{X \beta} + \bm{Z u} + \bm{\varepsilon} 
\qquad \bm{u} \sim N(\bm{0}, \bm{G})
\qquad \bm{\varepsilon} \sim N(\bm{0}, \bm{R}),$$
where (for balanced panels):\\
$\bm{X}$ is a $(n \! \times \! k)$ matrix, $k$ is the number of \textit{fixed effects},\\
$\bm{Z}\,$ is a $(n \! \times \! p)$ matrix, $p$ is the number of \textit{random effects},\\
$\bm{G}\,$ is a $(p \! \times \! p)$ variance-covariance matrix of the \textit{random effects},\\
$\bm{R}\,$ is a $(n \! \times \! n)$ variance-covariance matrix of errors.\\
\medskip
\begin{itemize}
    \item Independence between $\bm{u}$ and $\bm{\varepsilon}$ is assumed.\\
    \item  Often, $\bm{R}=\sigma^2_{\varepsilon} \bm{I}_n$ is assumed group-wise correlations.\\
    \item $\bm{G}\,$ is diagonal, if \textit{random effects} are mutually independent.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{More complex LME models}
\begin{frame}{More complex LME models - brief outline}
Different types of LME models exist:\\
\bigskip
\begin{itemize}
\item LME models with (multilevel) nested effects,
\medskip
\item LME models with crossed effects,
\medskip
\item Complex behavior of the error term in LME models can be addressed.
\medskip
\item LME models with non-Gaussian dependent variables \\(binary, Poisson, etc.).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME models with multilevel nested effects}
\textbf{Multi-level model example:} For 17 years, we follow a total of 86 individual states organized within 9 ``global-level'' regions (e.g. South America, Europe, Middle East, etc.).
\medskip
\begin{itemize}
\item $\texttt{GDP}_{tij}$ represents individual GDP per capita measurements for:\\
\smallskip
$t$-th time period, e.g. with values ($t= 2000, \dots, 2016)$.\\
$i$-th state nested within region $j$ ($i=1,\dots,M_j$),\\
$j$-th region ($j=1,\dots,9$),\\
\medskip
\item We fit \texttt{GDP} as a function of productivity \texttt{P} and unemployment \texttt{U}.\\
\smallskip
States are nested in regions, we have 2 levels of random intercepts: \\
~ $u_{0i(j)}$ for each state (within a region),\\
~ $v_{0j}$ for the regions,\\
~ random slopes can be added as well.
\bigskip
\item $\texttt{GDP}_{tij} = \beta_0 + \beta_1 \, \texttt{P}_{tij} 
+ \beta_2 \, \texttt{U}_{tij} + u_{0i(j)} + v_{0j}  + \varepsilon_{tij}.$
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME models with crossed random effects}
Crossed \textit{random effects} example:\\
\medskip
\begin{itemize}
\item Grunfeld (1958) analyzed data on 10 large U.S. corporations,
collected annually from 1935 to 1954 to investigate how \\investment \texttt{I} depends on market value \texttt{M} and capital stock \texttt{C}.\\
\medskip
\item Here, we want \textit{random effects} for a given firm and year.\\
\smallskip
We want the year effect to be the same across all firms, \\i.e. not nested within firms.
\bigskip
\item $\texttt{I}_{ti} = \beta_0 + \beta_1 \, \texttt{M}_{ti} 
+ \beta_2 \, \texttt{C}_{ti} + u_{0i} + v_{0t} + \varepsilon_{ti}.$\\
\medskip
where $i=1, \dots, 10$ and \\firms are followed over $t=1,\dots,20$ years.
\\(the usual ``$it$'' index ordering can be used as well)
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME models in R}
\begin{frame}{LME models in R}
\begin{itemize}
    \item \texttt{\{lme4\}} package \\ \smallskip
    \url{https://www.jstatsoft.org/article/view/v067i01/0}\\~\\
    \bigskip 
    \item \texttt{\{nlme\}} package \\ \smallskip
    \url{https://cran.r-project.org/web/packages/nlme/nlme.pdf}\\~\\
    \bigskip
    \item \url{https://www.r-bloggers.com/2017/12/linear-mixed-effect-models-in-r/}\\~\\
    \bigskip
    \item Finch, Bolin, Kelley: Multilevel Modeling Using R (2014).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\end{document}