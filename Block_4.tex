%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {
\usetheme{Madrid}
\usefonttheme{serif} 
\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the 
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{color}
\usepackage[czech]{babel}
\usepackage{lmodern}  
\usepackage{rotating}
\usepackage{scrextend}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage{bm}
%
\newcommand{\Rko}{\texttt{R~}} 
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------
\title[Block 4]{Praktikum z ekonometrie} % The short title appears at the bottom of every slide, the full title is only on the title page
\author{VŠE Praha} % Your name
\institute[4EK417] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
% Your institution for the title page
\medskip
\textit{Tomáš Formánek} % Your email address
}
\date{} % Date, can be changed to a custom date
%----------------------------------------------------------------------------------------
\begin{document}
\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}
%---------------------------------------------------------------------
\begin{frame}
\frametitle{Block 4 – Linear mixed models – Outline
} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%---------------------------------------------------------------------
\section{Introduction}
\begin{frame}{Introduction}
\small 
\textbf{Linear mixed model (LME)} is a generalization of linear (panel) model
\medskip
\begin{itemize}
\item LMEs \& longitudinal data: repeated measurements are performed on each individual. Several individuals are sampled. Number of observations may differ across individuals (for longitudinal \& hierarchical data).\\ \smallskip
\quad $y_{ti}$ - observation at time $t$ for $i$-th individual. \\  
\quad $y_{ij}$ - $i$th observation of $j$th individual (if time aspect secondary). \\ 
\bigskip
\item Nesting (hierarchical) data structure: CS data with multiple groups of observations (individuals, panels, etc.). \\ \smallskip
\quad $y_{ij}$ - observation for $i$-th company within $j$-th region. \\ 
\quad $y_{ij}$ - observation for $i$-th student within $j$-th school. \\ 
\medskip
We can group observations at multiple levels:\\
\smallskip
\quad $y_{tij}$ - time period $t$, region/county $i$, state $j$.\\ 
\bigskip
\item Please note that indices are ordered (left to right) from individual to highest level of aggregation. (alternative orderings exist in literature).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{Introduction}
\textbf{Linear mixed model (LME)} 
\medskip
\begin{itemize}
\item Nested/hierarchical structure of the LME model:
\medskip
\begin{itemize}
    \item Individuals $i$ (Level 1) are nested
    \medskip
    \item within $j$ groups (Level 2) with group-specific observation sizes $n_j$.
\end{itemize}
\medskip
\item One or more $\beta$-coefficients can vary across groups.
\bigskip
\item The same nesting/hierarchical framework applies to longitudinal data and their LME-based analysis:
\medskip
\begin{itemize}
    \item Observations $i$ (Level 1) are nested
    \smallskip
    \item within $j$ individuals (Level 2).
    \smallskip
    \item If appropriate, individuals can be nested in groups (Level 3) \dots 
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{Introduction}
\begin{itemize}
\item Mixed models are called ``mixed'', because the $\beta$-coefficients are \\a mix of fixed parameters and random variables
\smallskip 
\item Terms ``fixed'' and ``random'' have specific meaning for LMEs:\\ \smallskip
\begin{itemize}
\item A fixed coefficient is an unknown constant to be estimated. \smallskip
\item A random coefficient varies from ``group'' to ``group''. \\By ``group'', we mean Level 2 aggregation, if data have 2 levels. \\ - coefficients vary among schools (Level 2), not within school.\\
- coeffs. vary across individuals (Level 2), not over time (Level 1).
\end{itemize}
\smallskip
\item  LME models can have some added complexity:
\smallskip
\begin{itemize}
\item Multiple levels of nesting
\smallskip
\item Crossed random effects
\smallskip
\item Correlations between different random coefficients.


\end{itemize}
\smallskip
\item Random  coefficients are not estimated, but they can be predicted.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME model example}
\begin{frame}{LME model example}
\begin{itemize}
\item Data: \\London Education Authority Junior School Project
dataset, \\- we have 887 students ($i$) in 48 different schools ($j$),\\- we want to predict 5th-year math scores.
\medskip
\item We may start by ignoring the school grouping and any possible regressors -- we have a trivial model (\textit{single-mean} model):
$$ \texttt{math5}_{ij} = \beta_0~+~\varepsilon_{ij}, \quad i=1,\dots,n_j,  \quad j=1,\dots, M,  \quad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}) $$

where $M=48$ and $n_j$ differ among schools, $\texttt{math5}_{ij}$ is the observed  math score of $i$-th student at school $j$,
$\beta_0$ is the mean math score across our population (being sampled) and
$\varepsilon_{ij}$ is the individual deviation from overall mean.\\
\medskip
Population mean math score \& the variance of $\varepsilon$ are estimated by taking their sample counterparts. Any ``school effect'' is ignored.\\
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model example - continued}
\begin{itemize}
\item The school effect (differences among schools) may be incorporated in the model by allowing the mean of each school to be represented by a separate parameter (\textit{fixed effect})
$$ \texttt{math5}_{ij} = \beta_{0j}~+~\varepsilon_{ij}, \quad i=1,\dots,n_j,  \quad j=1,\dots, M,  \quad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}) $$

where $\beta_{0j}$ is the school-specific mean math score and
$\varepsilon_{ij}$ is the individual deviation from the school-specific mean.\\
\smallskip
\begin{itemize}
\item \Rko syntax: \texttt{lm(math5 $\sim$ School-1, data=...)}\\
$\Rightarrow~M=48$ school-specific intercepts are estimated.\\
\medskip
\item Using the terminology of LME, $\beta_{0j}$ are fixed. Hence:\\
\begin{itemize}
    \item \textbf{Estimated intercepts only model (refer to) the specific sample}  of schools, while -usually- the main interest is in the population from which the sample was drawn. \smallskip
    \item Regression does not provide an estimate of the between-school variability, which is also of central interest.
\end{itemize}
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept}
\begin{itemize}
\item \textit{Random effects} model can solve the above problems by treating the school effects as random variations around a population mean.
\medskip
\item \textit{Fixed effects} model can be reparametrized as: \\
\smallskip
\textcolor{blue}{$ y_{ij} = \beta_{0j} + \varepsilon_{ij}$} \\
\smallskip
$y_{ij} = \textcolor{orange}{\beta_0} + ( \beta_{0j} \textcolor{orange}{-\beta_0}) + \varepsilon_{ij}$,\\
\medskip
now, the \textit{random effect} $u_{0j} = \beta_{0j} - \beta_0$ can be used to replace the the \textit{fixed effect} $\beta_{0j}\,$:\\
\medskip
$u_{0j} = \beta_{0j} - \beta_0 ~~~ \Rightarrow ~~~ \beta_{0j} = \beta_0 + u_{0j}.$ Hence:\\  \smallskip
\textcolor{blue}{$ y_{ij} = \beta_{0} + u_{0j} + \varepsilon_{ij}.$}\\
\medskip
\item $u_{0j}$ is the school-specific deviation from overall mean $\beta_0$. \\
$u_{0j}$ is a random variable, specific for the $j$-th school, with zero
mean and unknown variance $\sigma^2_u$. \\ 
$u_{0j}$ is a \textit{random effect}, associated with the particular sample units (schools are selected at random from the population).\\ 
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept}
\begin{itemize}
\item The \textit{random effects} model is given as:
$$ y_{ij} = \beta_{0} + u_{0j} + \varepsilon_{ij}, \qquad u_{0j} \sim N(0,\sigma^2_u), \qquad \varepsilon_{ij} \sim N(0,\sigma^2_{\varepsilon}), $$
and we assume $u_{0j}$ are $iid$ and independent from $\varepsilon_{ij}$.\\
\smallskip
\begin{itemize}
\item Observations within the same school share the same random effect $u_{0j}$, hence are (positively) correlated with \textit{corr} = $\sigma^2_u \, / (\sigma^2_u + \sigma^2_{\varepsilon})$ \\ (see ICC on next slide).
\medskip
\item This \textit{random effects} model has three parameters: $\beta_{0},~ \sigma^2_u$ and $\sigma^2_{\varepsilon}$. (regardless of $M$, the number of schools).
\medskip
\item Note that the \textit{random effect} $u_{0j}$ ``looks like'' a coefficient, but we are interested in estimating $\sigma^2_u$.
\medskip
\item However, upon observed data (and estimated model), we do make predictions using fitted values of $\hat{u}_j$.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model: ICC}
\begin{itemize}
\item \textbf{ICC:} Intra class correlation (in a LME regression model) \qquad
$$ \textnormal{ICC}=\frac{\textnormal{Intercept variance}}{\textnormal{Intercept variance + Residual variance}} $$
\begin{itemize}
    \item ICC: Proportion of variance in the outcome variable that occurs between ``groups'' (schools) to the total variability present.
    \item Correlation between two ``individuals'' (students) randomly selected from the same ``group'' (school).
\end{itemize}
\medskip
\item Example 1\\ \medskip
$\texttt{math5}_{ij} = \beta_{0} + \beta_1 \, \texttt{math3}_{ij} + u_{0j} + \varepsilon_{ij},$\\ \medskip
where $\sigma^2_u = \textnormal{var}(u_{0j})$ and $\sigma^2_{\varepsilon} = \textnormal{var}(\varepsilon_{ij})$.\\ \smallskip
Here, $\textnormal{ICC}=\frac{\sigma^2_u}{\sigma^2_u + \sigma^2_{\varepsilon}}$  measures correlation between \texttt{math5}  observations (randomly chosen) within a given school.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model: ICC}
\begin{itemize}
\item \textbf{ICC:} Intra class correlation (in a LME regression model) \qquad
$$ \textnormal{ICC}=\frac{\textnormal{Intercept variance}}{\textnormal{Intercept variance + Residual variance}} $$
\medskip
\item Example 2\\ \medskip
In a longitudinal study, $y_{ij}$ measures the $i$-th response of the $j$-th individual. \\ \medskip
$y_{ij} = \beta_{0} + \bm{x}_{ij} \bm{\beta} + u_{0j} + \varepsilon_{ij},$\\ \medskip
Here, ICC measures correlation between $y_{ij}$  observations for \\a given individual.
\medskip
\item ICC is interpreted as the correlation between two \textbf{appropriately defined} observations from the same cluster/group \\(individual in a longitudinal study). 
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept}
\begin{itemize}
\item \textit{Random effects} model with random intercept:\\
\bigskip
Exogenous regressors are also used in LMEs (like in LRMs).\\
\smallskip
For example, \texttt{math5} grades depend on \texttt{math3} ($3{^{\textnormal{rd}}}$ year grades).\\
\medskip
$ y_{ij} = \beta_{0} + \beta_1 \, x_{ij} + u_{0j} + \varepsilon_{ij}, $\\
\medskip
i.e.\\
$ \texttt{math5}_{ij} = \beta_{0} + \beta_1 \, \texttt{math3}_{ij} + u_{0j} + \varepsilon_{ij}, $\\
\medskip
\begin{itemize}
\item Intercept is random.
\smallskip
\item Slope of the regression line for each school is fixed at $\beta_1$.\\
\dots \texttt{math3} has a \textit{fixed effect}.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME model with random intercept and slope}
\begin{itemize}
\item \textit{Random effects} model with random intercept and slope:\\
\medskip
If teaching is different from school to school, it would make
sense to have different slopes for each of the schools.\\
\medskip
Instead of \textit{fixed effects} (using interaction terms \texttt{math3:School}), \\we use random slopes: $ u_{1j} = \beta_{1j} - \beta_1 $. \\
\medskip
$ y_{ij} = \beta_{0} + u_{0j} + \beta_1 x_{ij}  + u_{1j} x_{ij}+ \varepsilon_{ij}, $ \\
\medskip
i.e.\\
\medskip
$\texttt{math5}_{ij} = \underbrace{\beta_{0} + \beta_1 \texttt{math3}_{ij}}_{\textit{fixed}}
+ \underbrace{u_{0j} + u_{1j}\, \texttt{math3}_{ij}}_{\textit{random}} 
+ \varepsilon_{ij}, $ \\
\medskip
\begin{itemize}
\item We can test whether this extra complexity is justified.
\smallskip
\item ${u}_{0j}$ and ${u}_{1j}$ are often correlated, their independence can be tested.
\smallskip
\item Fitted values of $\texttt{math5}_{ij}$ can be produced, along with $\hat{u}_{0j}$ and $\hat{u}_{1j}$.
\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME model in matrix form}
\begin{frame}{LME model in matrix form}
\begin{itemize}
\item Linear models 
$$\bm{y} = \bm{X \beta} + \bm{\varepsilon} 
\qquad \bm{\varepsilon} \sim N(\bm{0}, \,\sigma^2_{\varepsilon} \bm{I}),$$

\item can be generalized into LME models
$$\bm{y} = \bm{X \beta} + \bm{Z u} + \bm{\varepsilon} 
\qquad \bm{u} \sim N(\bm{0}, \bm{G})
\qquad \bm{\varepsilon} \sim N(\bm{0}, \bm{R}),$$
where (for balanced panels):\\
$\bm{X}$ is a $(n \! \times \! k)$ matrix, $k$ is the number of \textit{fixed effects},\\
$\bm{Z}\,$ is a $(n \! \times \! p)$ matrix, $p$ is the number of \textit{random effects},\\
$\bm{G}\,$ is a $(p \! \times \! p)$ variance-covariance matrix of the \textit{random effects},\\
$\bm{R}\,$ is a $(n \! \times \! n)$ variance-covariance matrix of errors.\\
\medskip
Independence between $\bm{u}$ and $\bm{\varepsilon}$ is assumed,\\
Often, $\bm{R}=\sigma^2_{\varepsilon} \bm{I}$, can be generalized for group-wise correlations,\\
$\bm{G}\,$ is diagonal if \textit{random effects} are mutually independent.
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{More complex LME models}
\begin{frame}{More complex LME models - brief outline}
Different types of LME models exist:\\
\bigskip
\begin{itemize}
\item LME models with (multilevel) nested effects,
\medskip
\item LME models with crossed effects,
\medskip
\item Complex behavior of the error term in LME models can be addressed.
\medskip
\item LME models with non-Gaussian (Binary, Poisson, etc.).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME models with (multilevel) nested effects}
\textbf{Multi-level model example:} we follow a total of 48 individual states within 9 regions and across 17 years.
\medskip
\begin{itemize}
\item $\texttt{GDP}_{tij}$ represents individual GDP per capita measurements for:\\
\smallskip
$t$-th time period, e.g. with values ($t= 1990, \dots, 2006)$.\\
$i$-th state nested within region $j$ ($i=1,\dots,M_j$),\\
$j$-th region ($j=1,\dots,9$),\\



\medskip
\item We fit \texttt{GDP} as a function of productivity \texttt{P} and unemployment \texttt{U}.\\
\smallskip
We treat states as nested within regions, so we have 2 levels of random intercepts: one due to the regions ($v_{0j}$), and another due to the state within region (random slopes can be added as well).
\bigskip
\item $\texttt{GDP}_{tij} = \beta_0 + \beta_1 \, \texttt{P}_{tij} 
+ \beta_2 \, \texttt{U}_{tij} + u_{0i(j)} + v_{0j}  + \varepsilon_{tij}.$
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\begin{frame}{LME models with crossed random effects}
Crossed \textit{random effects} example:\\
\medskip
\begin{itemize}
\item Grunfeld (1958) analyzed data on 10 large U.S. corporations,
collected annually from 1935 to 1954 to investigate how \\investment \texttt{I} depends on market value \texttt{M} and capital stock \texttt{C}.\\
\medskip
\item Here, we want \textit{random effects} for a given firm and year.\\
\smallskip
However, we want the year effect to be the same across all firms, i.e. not nested within firms.
\bigskip
\item $\texttt{I}_{it} = \beta_0 + \beta_1 \, \texttt{M}_{it} 
+ \beta_2 \, \texttt{C}_{it} + u_{0i} + v_{0t} + \varepsilon_{it}.$\\
\medskip
where $i=1, \dots, 10$ and \\firms are followed over $t=1,\dots,20$ years.
\\(note the usual ``$it$'' index ordering is used here)
\end{itemize}
\end{frame}
%---------------------------------------------------------------------
\section{LME models in R}
\begin{frame}{LME models in R}
\begin{itemize}
    \item \texttt{\{lme4\}} package \\ \smallskip
    \url{https://www.jstatsoft.org/article/view/v067i01/0}\\~\\
    \bigskip 
    \item \texttt{\{nlme\}} package \\ \smallskip
    \url{https://cran.r-project.org/web/packages/nlme/nlme.pdf}\\~\\
    \bigskip
    \item Finch, Bolin, Kelley: Multilevel Modeling Using R (2014).
\end{itemize}
\end{frame}
%---------------------------------------------------------------------






\end{document}