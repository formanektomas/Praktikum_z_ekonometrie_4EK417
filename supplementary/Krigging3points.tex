\documentclass{article}
\usepackage{amsmath}

\begin{document}

\section*{Example: Ordinary Kriging with Three Points}

\subsection*{Data Points}
\begin{itemize}
    \item Known data points: \( Z(x_1) \), \( Z(x_2) \), \( Z(x_3) \)
    \item Unsampled location: \( x_0 \)
\end{itemize}

\subsection*{Weights}
Weights to be determined: \( \lambda_1 \), \( \lambda_2 \), \( \lambda_3 \) such that the estimate \( \hat{Z}(x_0) \) at location \( x_0 \) is a weighted sum of the known values:
   $$
   \hat{Z}(x_0) = \lambda_1 Z(x_1) + \lambda_2 Z(x_2) + \lambda_3 Z(x_3)
   $$

\subsection*{Function to Minimize}

In ordinary kriging, the goal is to minimize the estimation variance, which can be expressed as:

$$
\text{Var}(\hat{Z}(x_0)) = \sum_{i=1}^{3} \sum_{j=1}^{3} \lambda_i \lambda_j \gamma(x_i, x_j) + \sum_{i=1}^{3} \lambda_i \gamma(x_i, x_0)
$$

\subsection*{Constraint}

The constraint is that the sum of the weights must equal 1:

$$
\sum_{i=1}^{3} \lambda_i = 1
$$


\subsection*{Lagrangian Function}
The Lagrangian function for ordinary kriging is:
\[
L(\lambda_1, \lambda_2, \lambda_3, \mu) = \sum_{i=1}^{3} \sum_{j=1}^{3} \lambda_i \lambda_j \gamma(x_i, x_j) + \sum_{i=1}^{3} \lambda_i \gamma(x_i, x_0) + \mu \left( \sum_{i=1}^{3} \lambda_i - 1 \right)
\]
where \( \gamma(x_i, x_j) \) is the semivariance between points \( x_i \) and \( x_j \), and \( \mu \) is the Lagrange multiplier.

\newpage
\subsection*{Partial Derivatives}
Taking the partial derivatives with respect to \( \lambda_i \) and \( \mu \):
\[
\frac{\partial L}{\partial \lambda_i} = \sum_{j=1}^{3} \lambda_j \gamma(x_i, x_j) + \gamma(x_i, x_0) + \mu = 0 \quad \text{for } i = 1, 2, 3
\]
\[
\frac{\partial L}{\partial \mu} = \sum_{i=1}^{3} \lambda_i - 1 = 0
\]

\subsection*{System of Equations}
Rearranging the partial derivatives, we get the following system of equations:
\[
\begin{cases}
\lambda_1 \gamma(x_1, x_1) + \lambda_2 \gamma(x_1, x_2) + \lambda_3 \gamma(x_1, x_3) + \mu = \gamma(x_1, x_0) \\
\lambda_1 \gamma(x_2, x_1) + \lambda_2 \gamma(x_2, x_2) + \lambda_3 \gamma(x_2, x_3) + \mu = \gamma(x_2, x_0) \\
\lambda_1 \gamma(x_3, x_1) + \lambda_2 \gamma(x_3, x_2) + \lambda_3 \gamma(x_3, x_3) + \mu = \gamma(x_3, x_0) \\
\lambda_1 + \lambda_2 + \lambda_3 = 1
\end{cases}
\]

By solving this system of equations, we can determine the weights \( \lambda_1 \), \( \lambda_2 \), and \( \lambda_3 \) that minimize the estimation variance while ensuring the sum of the weights is one.

\end{document}